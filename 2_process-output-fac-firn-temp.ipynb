{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert FAC from output .pro files to .nc files\n",
    "\n",
    "#### Created by Megan Thompson-Munson (2023)\n",
    "\n",
    "\n",
    "**Input:** `/scratch/alpine/metm9666/project-2_output-4/*DEC*.pro`\n",
    "\n",
    "**Output:** `/scratch/alpine/metm9666/project-2_processed-output-4/FAC-*.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import netCDF4 as nc\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files: 3450\n",
      "# of locations: 1725\n"
     ]
    }
   ],
   "source": [
    "# Print number of files\n",
    "nfiles = len(glob.glob('/pl/active/metm-greenland/project-2_output/*.pro'))\n",
    "print('# of files: {}'.format(nfiles))\n",
    "print('# of locations: {:.0f}'.format(nfiles/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('/pl/active/metm-greenland/project-2_output/*DEC*.pro'))\n",
    "# files = sorted(glob.glob('/pl/active/metm-greenland/project-2_output/*INC*.pro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATION_PARAMETERS]\n",
      "\n",
      "StationName= 0\n",
      "\n",
      "Latitude= 79.00000000\n",
      "\n",
      "Longitude= -62.50000000\n",
      "\n",
      "Altitude= 1197\n",
      "\n",
      "SlopeAngle= 0.00\n",
      "\n",
      "SlopeAzi= 0.00\n",
      "\n",
      "\n",
      "\n",
      "[HEADER]\n",
      "\n",
      "#2023-06-23T17:51:25, Snowpack POLAR version 3.0.0 run by \"metm9666\" (research mode)\n",
      "\n",
      "0500,Date\n",
      "\n",
      "0501,nElems,height [> 0: top, < 0: bottom of elem.] (cm)\n",
      "\n",
      "0502,nElems,element density (kg m-3)\n",
      "\n",
      "0503,nElems,element temperature (degC)\n",
      "\n",
      "0504,nElems,element mk (1)\n",
      "\n",
      "0505,nElems,element age (days)\n",
      "\n",
      "0506,nElems,liquid water content by volume (%)\n",
      "\n",
      "0508,nElems,dendricity (1)\n",
      "\n",
      "0509,nElems,sphericity (1)\n",
      "\n",
      "0510,nElems,coordination number (1)\n",
      "\n",
      "0511,nElems,bond size (mm)\n",
      "\n",
      "0512,nElems,grain size (mm)\n",
      "\n",
      "0513,nElems,grain type (Swiss Code F1F2F3)\n",
      "\n",
      "0514,3,grain type, grain size (mm), and density (kg m-3) of SH at surface\n",
      "\n",
      "0515,nElems,ice volume fraction (%)\n",
      "\n",
      "0516,nElems,air volume fraction (%)\n",
      "\n",
      "0517,nElems,stress in (kPa)\n",
      "\n",
      "0518,nElems,viscosity (GPa s)\n",
      "\n",
      "0519,nElems,soil volume fraction (%)\n",
      "\n",
      "0520,nElems,temperature gradient (K m-1)\n",
      "\n",
      "0521,nElems,thermal conductivity (W K-1 m-1)\n",
      "\n",
      "0522,nElems,absorbed shortwave radiation (W m-2)\n",
      "\n",
      "0523,nElems,viscous deformation rate (1.e-6 s-1)\n",
      "\n",
      "0529,nElems,Stress rate CDot (Pa s-1)\n",
      "\n",
      "0535,nElems,optical equivalent grain size (mm)\n",
      "\n",
      "0602,nElems,grain size difference (mm)\n",
      "\n",
      "0603,nElems,hardness difference (1)\n",
      "\n",
      "\n",
      "\n",
      "[DATA]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(files[0]) as f:\n",
    "    for h in range(39):\n",
    "        header = f.readline()\n",
    "        print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "dateList = []\n",
    "latList = []\n",
    "lonList = []\n",
    "facList = []\n",
    "\n",
    "# Read in SNOWPACK data\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    # Get .pro file\n",
    "    pro_file = files[i]\n",
    "\n",
    "    # Read data line by line\n",
    "    with open(pro_file) as f:\n",
    "\n",
    "        # Read in header information\n",
    "        for h in range(39):\n",
    "            header = f.readline()\n",
    "            if h == 1:\n",
    "                station = int(header[13:])\n",
    "            if h == 2:\n",
    "                latitude = float(header[10:-1])\n",
    "                latList.append(latitude)\n",
    "            if h == 3:\n",
    "                longitude = float(header[11:-1])\n",
    "                lonList.append(longitude)\n",
    "            if h == 4:\n",
    "                elevation = float(header[9:-1])\n",
    "\n",
    "        # Create empty lists for each file,\n",
    "        # which represents data from all times at a single location\n",
    "        dateLoc = []\n",
    "        depthLoc = []\n",
    "        thicknessLoc = []\n",
    "        densityLoc = []\n",
    "        temperatureLoc = []\n",
    "        waterLoc = []\n",
    "        iceLoc = []\n",
    "        airLoc = []\n",
    "\n",
    "        # Read in data below header using line code and omitting first two \n",
    "        # items in list since they are the code and number of elements\n",
    "        for line in f:\n",
    "            if line.startswith('0500'): # Date\n",
    "                date = datetime.datetime.strptime(line[5:24],'%d.%m.%Y %H:%M:%S')\n",
    "                dateLoc.append(date)\n",
    "            if line.startswith('0501'): # Height\n",
    "                height = np.array(list(map(float,line.split(',')))[2:])/100\n",
    "                depth = (height-height[-1])*-1\n",
    "                depthLoc.append(depth)\n",
    "                thicknessShort = np.array(height[1:]-height[:-1])\n",
    "                thickness = np.insert(thicknessShort,0,height[0])\n",
    "                thicknessLoc.append(thickness)\n",
    "            if line.startswith('0516'): # Air\n",
    "                air = list(map(float,line.split(',')))[2:]\n",
    "                airLoc.append(np.array(air)/100)\n",
    "\n",
    "    # Close file\n",
    "    f.close()\n",
    "\n",
    "    facLoc = []\n",
    "\n",
    "    # Calculate firn air content\n",
    "    for t in range(len(dateLoc)):\n",
    "        thicknessTemp = thicknessLoc[t]\n",
    "        airTemp = airLoc[t]\n",
    "        facTemp = np.sum(thicknessTemp*airTemp)\n",
    "        facLoc.append(facTemp)\n",
    "\n",
    "    # Append all lists\n",
    "    dateList.append(dateLoc)\n",
    "    facList.append(facLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with all values\n",
    "df = pd.DataFrame(data={'lat':latList,'lon':lonList,'FAC':facList})\n",
    "\n",
    "# # Loop through to see if any are too short\n",
    "# for i in range(len(df)):\n",
    "#     nfac = len(df.FAC[i])\n",
    "#     if nfac != 5219:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If any are too short, replace with NaN\n",
    "df_copy = df.copy()\n",
    "df_copy.loc[68,'FAC'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with all values\n",
    "dfPivot = df_copy.pivot(index='lat',columns='lon',values='FAC')\n",
    "\n",
    "# Create list of data arrays for each timestamp\n",
    "das = []\n",
    "for i in range(len(dateList[0])):\n",
    "#     dfTemp = dfPivot.applymap(lambda x: x[i],na_action='ignore') # na_action not available on Summit\n",
    "    dfTemp = dfPivot.applymap(lambda x: x[i] if type(x) is list else np.nan)\n",
    "    da = xr.DataArray(data=dfTemp.values,\n",
    "                      dims=['lat','lon'],\n",
    "                      coords=[dfTemp.index,dfTemp.columns])\n",
    "    da.attrs['units'] = 'm'\n",
    "    das.append(da)\n",
    "\n",
    "# Concat the data arrays and add the time dimension\n",
    "daConcat = xr.concat(das, pd.Index(dateList[0],name='time'))\n",
    "ds = xr.Dataset({'fac':daConcat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.to_netcdf(path='/scratch/alpine/metm9666/project-2_processed-output-4/FAC-DEC.nc',\n",
    "#              mode='w',format='NETCDF4')\n",
    "ds.to_netcdf(path='/scratch/alpine/metm9666/project-2_processed-output-4/FAC-INC.nc',\n",
    "             mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firn temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "dateList = []\n",
    "latList = []\n",
    "lonList = []\n",
    "temperatureList = []\n",
    "\n",
    "# Read in SNOWPACK data\n",
    "for i in range(len(files)):\n",
    "# for i in range(1):\n",
    "    \n",
    "    # Get .pro file\n",
    "    pro_file = files[i]\n",
    "\n",
    "    # Read data line by line\n",
    "    with open(pro_file) as f:\n",
    "\n",
    "        # Read in header information\n",
    "        for h in range(39):\n",
    "            header = f.readline()\n",
    "            if h == 1:\n",
    "                station = int(header[13:])\n",
    "            if h == 2:\n",
    "                latitude = float(header[10:-1])\n",
    "                latList.append(latitude)\n",
    "            if h == 3:\n",
    "                longitude = float(header[11:-1])\n",
    "                lonList.append(longitude)\n",
    "            if h == 4:\n",
    "                elevation = float(header[9:-1])\n",
    "\n",
    "        # Create empty lists for each file,\n",
    "        # which represents data from all times at a single location\n",
    "        dateLoc = []\n",
    "        depthLoc = []\n",
    "        temperatureLoc = []\n",
    "\n",
    "        # Read in data below header using line code and omitting first two \n",
    "        # items in list since they are the code and number of elements\n",
    "        for line in f:\n",
    "            if line.startswith('0500'): # Date\n",
    "                date = datetime.datetime.strptime(line[5:24],'%d.%m.%Y %H:%M:%S')\n",
    "                dateLoc.append(date)\n",
    "            if line.startswith('0501'): # Height\n",
    "                height = np.array(list(map(float,line.split(',')))[2:])/100\n",
    "                depth = (height-height[-1])*-1\n",
    "                depthLoc.append(depth)\n",
    "            if line.startswith('0503'): # Temperature\n",
    "                temperature = list(map(float,line.split(',')))[2:]\n",
    "#                 temperatureLoc.append(temperature)\n",
    "                temperatureLoc.append(np.mean(temperature))\n",
    "\n",
    "    # Close file\n",
    "    f.close()\n",
    "\n",
    "#     tempLoc = []\n",
    "\n",
    "#     # Get temperature at closest depth to 20 m\n",
    "#     for t in range(len(dateLoc)):\n",
    "#         depth20_idx = min(range(len(depthLoc[t])), key=lambda j: abs(depthLoc[t][j]-20))\n",
    "#         temp20 = temperatureLoc[t][depth20_idx]\n",
    "#         tempLoc.append(temp20)\n",
    "\n",
    "    # Append all lists\n",
    "    dateList.append(dateLoc)\n",
    "    temperatureList.append(temperatureLoc)\n",
    "#     tempList.append(tempLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with all values\n",
    "df = pd.DataFrame(data={'lat':latList,'lon':lonList,'temperature':temperatureList})\n",
    "\n",
    "# # Loop through to see if any are too short\n",
    "# for i in range(len(df)):\n",
    "#     nfac = len(df.FAC[i])\n",
    "#     if nfac != 5219:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If any are too short, replace with NaN\n",
    "df_copy = df.copy()\n",
    "df_copy.loc[68,'temperature'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with all values\n",
    "dfPivot = df_copy.pivot(index='lat',columns='lon',values='temperature')\n",
    "\n",
    "# Create list of data arrays for each timestamp\n",
    "das = []\n",
    "for i in range(len(dateList[0])):\n",
    "#     dfTemp = dfPivot.applymap(lambda x: x[i],na_action='ignore') # na_action not available on Summit\n",
    "    dfTemp = dfPivot.applymap(lambda x: x[i] if type(x) is list else np.nan)\n",
    "    da = xr.DataArray(data=dfTemp.values,\n",
    "                      dims=['lat','lon'],\n",
    "                      coords=[dfTemp.index,dfTemp.columns])\n",
    "    da.attrs['units'] = 'deg C'\n",
    "    das.append(da)\n",
    "\n",
    "# Concat the data arrays and add the time dimension\n",
    "daConcat = xr.concat(das, pd.Index(dateList[0],name='time'))\n",
    "ds = xr.Dataset({'temperature':daConcat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(path='/scratch/alpine/metm9666/project-2_processed-output-4/firn-temperature-mean-DEC.nc',\n",
    "             mode='w',format='NETCDF4')\n",
    "# ds.to_netcdf(path='/scratch/alpine/metm9666/project-2_processed-output-4/firn-temperature-mean-INC.nc',\n",
    "#              mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpack",
   "language": "python",
   "name": "snowpack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
